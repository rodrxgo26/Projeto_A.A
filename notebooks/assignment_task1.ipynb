{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae49b388",
   "metadata": {},
   "source": [
    "# Assignment — Tasks 1.1, 1.2 and 2.1 (Inline, CSV-only)\n",
    "\n",
    "Este notebook contém:\n",
    "- **Task 1.1**: preparação de dados, verificação de 258 vs 257, anomalias e colisões, trajetórias (plots inline);\n",
    "- **Task 1.2**: baseline `StandardScaler → LinearRegression`, RMSE (train/val/test), y–ŷ (inline), submissão `baseline-model.csv`;\n",
    "- **Task 2.1**: função `validate_poly_regression(...)`, testes por grau (1–14), `LinearRegression` e `RidgeCV`, gráfico RMSE vs grau + nº de features, 10 execuções e histograma do grau ótimo.\n",
    "\n",
    "**Nota:** Os gráficos são mostrados **inline** (não se guardam imagens). Apenas são guardados **CSVs** de submissão.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731bb215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports & config\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Config\n",
    "SEED = 123\n",
    "TRAIN_PATH = '../data/X_train.csv'\n",
    "TEST_PATH  = '../data/X_test.csv'\n",
    "\n",
    "SPLIT_TRAIN = 0.70\n",
    "SPLIT_VAL   = 0.15\n",
    "SPLIT_TEST  = 0.15\n",
    "assert abs(SPLIT_TRAIN + SPLIT_VAL + SPLIT_TEST - 1.0) < 1e-9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a443f339",
   "metadata": {},
   "source": [
    "## Task 1.1 — Data Preparation & Validation (Inline Plots, CSV-only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e597e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train = pd.read_csv(TRAIN_PATH)\n",
    "test  = pd.read_csv(TEST_PATH)\n",
    "\n",
    "print('Train shape:', train.shape, '| Test shape:', test.shape)\n",
    "display(train.head())\n",
    "\n",
    "# Unique time steps\n",
    "unique_t = np.sort(train['t'].unique())\n",
    "STEPS_PER_TRAJ = len(unique_t)\n",
    "print('Unique time steps (t):', STEPS_PER_TRAJ, '| t[0]=', unique_t[0], '| t[-1]=', unique_t[-1])\n",
    "\n",
    "# Trajectory/step indices\n",
    "train = train.reset_index(drop=True)\n",
    "train['traj_idx'] = train.index // STEPS_PER_TRAJ\n",
    "train['step_idx'] = train.index % STEPS_PER_TRAJ\n",
    "\n",
    "# Count per trajectory\n",
    "per_traj_counts = train.groupby('traj_idx').size()\n",
    "display(per_traj_counts.describe())\n",
    "\n",
    "# Check 258 lines per trajectory\n",
    "expected_lines = 258\n",
    "n_traj = per_traj_counts.shape[0]\n",
    "n_exact_258 = int((per_traj_counts == expected_lines).sum())\n",
    "print(f'Trajetórias com exatamente {expected_lines} linhas: {n_exact_258}/{n_traj}')\n",
    "if STEPS_PER_TRAJ != expected_lines:\n",
    "    print('NOTA: Este dataset tem', STEPS_PER_TRAJ, 'instantes únicos de t, não 258. '\n",
    "          'Documenta nos slides. O código lida com ambos.')\n",
    "\n",
    "# Attach initial conditions (step 0) to all rows\n",
    "init_rows = (train[train['step_idx']==0]\n",
    "             [['traj_idx','x_1','y_1','x_2','y_2','x_3','y_3']]\n",
    "             .rename(columns={'x_1':'x0_1','y_1':'y0_1','x_2':'x0_2','y_2':'y0_2','x_3':'x0_3','y_3':'y0_3'}))\n",
    "train = train.merge(init_rows, on='traj_idx', how='left')\n",
    "\n",
    "# Check zero velocities at t=0\n",
    "vel_zero_sum = (train[train['step_idx']==0][['v_x_1','v_y_1','v_x_2','v_y_2','v_x_3','v_y_3']].abs().sum().sum())\n",
    "print('Soma abs de velocidades em t=0 (deve ser 0):', float(vel_zero_sum))\n",
    "\n",
    "# Collision detection\n",
    "target_cols  = ['x_1','y_1','x_2','y_2','x_3','y_3']\n",
    "\n",
    "def first_zero_step(g):\n",
    "    mask = (g[target_cols].abs().sum(axis=1) == 0.0)\n",
    "    idx = np.where(mask.values)[0]\n",
    "    return int(idx[0]) if len(idx)>0 else np.nan\n",
    "\n",
    "first_zero = train.groupby('traj_idx', group_keys=False).apply(first_zero_step)\n",
    "n_collide  = int(first_zero.notna().sum())\n",
    "print('Trajetórias com colisão:', n_collide)\n",
    "\n",
    "# Verify rule: after first zero, all next are zero\n",
    "violations = 0\n",
    "for tidx, fz in first_zero.dropna().items():\n",
    "    fz = int(fz)\n",
    "    g = train[train['traj_idx']==tidx].sort_values('step_idx')\n",
    "    tail = g[g['step_idx']>=fz][target_cols].abs().sum(axis=1)\n",
    "    if not np.all(tail.values == 0.0):\n",
    "        violations += 1\n",
    "print('Violam a regra \"após zero, tudo zero\":', violations)\n",
    "\n",
    "# Remove post-collision rows (keep valid targets only)\n",
    "valid_mask  = (train[target_cols].abs().sum(axis=1) > 0.0)\n",
    "train_valid = train[valid_mask].copy()\n",
    "\n",
    "# Features to match X_test\n",
    "feature_cols = ['t','x0_1','y0_1','x0_2','y0_2','x0_3','y0_3']\n",
    "print('train_valid shape:', train_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8a964c",
   "metadata": {},
   "source": [
    "### Visualizações (inline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ec5c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograma do primeiro step zero (colisão)\n",
    "if n_collide > 0:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    first_zero.dropna().astype(int).plot(kind='hist', bins=30)\n",
    "    plt.title('Distribuição do primeiro step zero (colisão)')\n",
    "    plt.xlabel('step_idx da colisão')\n",
    "    plt.ylabel('freq')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Sem colisões detetadas para o histograma.')\n",
    "\n",
    "# 3 trajetórias aleatórias\n",
    "np.random.seed(SEED)\n",
    "all_traj = train['traj_idx'].unique()\n",
    "sample_trajs = np.random.choice(all_traj, size=min(3, len(all_traj)), replace=False)\n",
    "\n",
    "for i, ti in enumerate(sample_trajs, start=1):\n",
    "    g = train[train['traj_idx']==ti].sort_values('step_idx')\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.plot(g['x_1'], g['y_1'], label='Body 1')\n",
    "    plt.plot(g['x_2'], g['y_2'], label='Body 2')\n",
    "    plt.plot(g['x_3'], g['y_3'], label='Body 3')\n",
    "    plt.title(f'Trajetória {ti} (sample #{i})')\n",
    "    plt.xlabel('x'); plt.ylabel('y'); plt.axis('equal'); plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Uma trajetória com colisão (se existir)\n",
    "if n_collide > 0:\n",
    "    collide_tid = first_zero.dropna().index[0]\n",
    "    g = train[train['traj_idx']==collide_tid].sort_values('step_idx')\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.plot(g['x_1'], g['y_1'], label='Body 1')\n",
    "    plt.plot(g['x_2'], g['y_2'], label='Body 2')\n",
    "    plt.plot(g['x_3'], g['y_3'], label='Body 3')\n",
    "    plt.title(f'Trajetória com colisão (id={collide_tid})')\n",
    "    plt.xlabel('x'); plt.ylabel('y'); plt.axis('equal'); plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372e9818",
   "metadata": {},
   "source": [
    "## Task 1.2 — Baseline: StandardScaler + LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624d4c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split 70/15/15 por trajetória (sem vazamento)\n",
    "traj_ids = np.array(sorted(train_valid['traj_idx'].unique()))\n",
    "n_traj = len(traj_ids)\n",
    "traj_train, traj_temp = train_test_split(traj_ids, test_size=(SPLIT_VAL + SPLIT_TEST), random_state=SEED, shuffle=True)\n",
    "traj_val, traj_test   = train_test_split(traj_temp, test_size=(SPLIT_TEST/(SPLIT_VAL+SPLIT_TEST)), random_state=SEED, shuffle=True)\n",
    "\n",
    "def subset_by_trajs(df, trajs): return df[df['traj_idx'].isin(trajs)]\n",
    "\n",
    "df_tr = subset_by_trajs(train_valid, traj_train)\n",
    "df_va = subset_by_trajs(train_valid, traj_val)\n",
    "df_te = subset_by_trajs(train_valid, traj_test)\n",
    "\n",
    "print('Traj counts -> train/val/test:', len(traj_train), len(traj_val), len(traj_test))\n",
    "print('Proporções (traj):', \n",
    "      round(len(traj_train)/n_traj,3), \n",
    "      round(len(traj_val)/n_traj,3), \n",
    "      round(len(traj_test)/n_traj,3))\n",
    "\n",
    "# Prova de não-sobreposição das condições iniciais\n",
    "def initial_tuple(df):\n",
    "    starts = df[df['step_idx']==0][['x0_1','y0_1','x0_2','y0_2','x0_3','y0_3']].copy()\n",
    "    starts['key'] = list(map(tuple, starts.values))\n",
    "    return set(starts['key'].tolist())\n",
    "\n",
    "init_tr = initial_tuple(df_tr); init_va = initial_tuple(df_va); init_te = initial_tuple(df_te)\n",
    "overlap_any = (init_tr & init_va) | (init_tr & init_te) | (init_va & init_te)\n",
    "print('Sobreposição de condições iniciais entre conjuntos? ->', 'SIM' if len(overlap_any)>0 else 'NÃO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47871847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrices\n",
    "feature_cols = ['t','x0_1','y0_1','x0_2','y0_2','x0_3','y0_3']\n",
    "target_cols  = ['x_1','y_1','x_2','y_2','x_3','y_3']\n",
    "\n",
    "X_tr = df_tr[feature_cols].values\n",
    "y_tr = df_tr[target_cols].values\n",
    "X_va = df_va[feature_cols].values\n",
    "y_va = df_va[target_cols].values\n",
    "X_te_local = df_te[feature_cols].values\n",
    "y_te_local = df_te[target_cols].values\n",
    "\n",
    "# Baseline pipeline\n",
    "baseline = Pipeline([('scaler', StandardScaler()), ('linreg', LinearRegression())])\n",
    "baseline.fit(X_tr, y_tr)\n",
    "\n",
    "y_pred_tr = baseline.predict(X_tr)\n",
    "y_pred_va = baseline.predict(X_va)\n",
    "y_pred_te = baseline.predict(X_te_local)\n",
    "\n",
    "rmse_tr = np.sqrt(mean_squared_error(y_tr, y_pred_tr))\n",
    "rmse_va = np.sqrt(mean_squared_error(y_va, y_pred_va))\n",
    "rmse_te = np.sqrt(mean_squared_error(y_te_local, y_pred_te))\n",
    "\n",
    "print(f'RMSE treino:      {rmse_tr:.6f}')\n",
    "print(f'RMSE validação:   {rmse_va:.6f}')\n",
    "print(f'RMSE teste local: {rmse_te:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbf8cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y–ŷ plot (validação) inline\n",
    "def plot_y_yhat_inline(y_test, y_pred):\n",
    "    labels = ['x_1','y_1','x_2','y_2','x_3','y_3']\n",
    "    MAX = 500\n",
    "    idx = np.random.choice(len(y_test), min(MAX, len(y_test)), replace=False)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for i in range(6):\n",
    "        x0 = np.min(y_test[idx,i]); x1 = np.max(y_test[idx,i])\n",
    "        ax = plt.subplot(3,2,i+1)\n",
    "        ax.scatter(y_test[idx,i], y_pred[idx,i], s=8)\n",
    "        ax.plot([x0,x1],[x0,x1])\n",
    "        ax.set_xlabel('True '+labels[i]); ax.set_ylabel('Predicted '+labels[i])\n",
    "        ax.set_aspect('equal','box')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_y_yhat_inline(y_va, y_pred_va)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95721084",
   "metadata": {},
   "source": [
    "### Submissão Kaggle — `baseline-model.csv` (treino em train+val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130a378a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_full = pd.concat([df_tr[feature_cols], df_va[feature_cols]], axis=0).values\n",
    "y_tr_full = pd.concat([df_tr[target_cols],  df_va[target_cols]],  axis=0).values\n",
    "\n",
    "baseline_full = Pipeline([('scaler', StandardScaler()), ('linreg', LinearRegression())]).fit(X_tr_full, y_tr_full)\n",
    "\n",
    "X_submit = test[['t','x0_1','y0_1','x0_2','y0_2','x0_3','y0_3']].values\n",
    "y_submit = baseline_full.predict(X_submit)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'Id': test['Id'],\n",
    "    'x_1': y_submit[:,0],\n",
    "    'y_1': y_submit[:,1],\n",
    "    'x_2': y_submit[:,2],\n",
    "    'y_2': y_submit[:,3],\n",
    "    'x_3': y_submit[:,4],\n",
    "    'y_3': y_submit[:,5],\n",
    "})\n",
    "submission.to_csv('../outputs/baseline-model.csv', index=False)\n",
    "print('Wrote baseline-model.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ff904c",
   "metadata": {},
   "source": [
    "## Task 2.1 — Polynomial Regression Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a0d33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_poly_regression(X_train, y_train, X_val, y_val, \n",
    "                             regressor=None, \n",
    "                             degrees=range(1,15), \n",
    "                             subset_frac=None, \n",
    "                             random_state=None):\n",
    "    \"\"\"Valida regressão polinomial para vários graus e retorna o melhor pipeline e RMSE.\"\n",
    "    \"\"\"\n",
    "    if regressor is None or regressor == 'linear':\n",
    "        reg = LinearRegression()\n",
    "    elif regressor == 'ridge':\n",
    "        reg = RidgeCV(alphas=np.logspace(-4, 4, 13))\n",
    "    else:\n",
    "        reg = regressor\n",
    "    \n",
    "    # Optional subsample for speed\n",
    "    if subset_frac is not None and 0 < subset_frac < 1.0:\n",
    "        n_sub = max(1000, int(len(X_train) * subset_frac))\n",
    "        rng = np.random.RandomState(random_state)\n",
    "        idx = rng.choice(len(X_train), size=n_sub, replace=False)\n",
    "        X_tr = X_train[idx]\n",
    "        y_tr = y_train[idx]\n",
    "    else:\n",
    "        X_tr, y_tr = X_train, y_train\n",
    "    \n",
    "    best_rmse = np.inf\n",
    "    best_model = None\n",
    "    rmse_by_d = []\n",
    "    feats_by_d = []\n",
    "    results = {}\n",
    "    \n",
    "    for d in degrees:\n",
    "        poly = PolynomialFeatures(degree=d, include_bias=False)\n",
    "        pipe = Pipeline([('poly', poly), ('scaler', StandardScaler()), ('reg', reg)])\n",
    "        pipe.fit(X_tr, y_tr)\n",
    "        y_pred = pipe.predict(X_val)\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "        n_out_feats = pipe.named_steps['poly'].n_output_features_\n",
    "        results[d] = {'rmse': rmse, 'n_features': n_out_feats}\n",
    "        rmse_by_d.append(rmse)\n",
    "        feats_by_d.append(n_out_feats)\n",
    "        print(f\"grau={d:2d} | n_features={n_out_feats:5d} | RMSE_val={rmse:.6f}\")\n",
    "        if rmse < best_rmse:\n",
    "            best_rmse = rmse\n",
    "            best_model = pipe\n",
    "    \n",
    "    # Plot inline: RMSE vs degree and number of features (twin axis)\n",
    "    fig, ax1 = plt.subplots(figsize=(7,4))\n",
    "    ax1.plot(list(degrees), rmse_by_d, marker='o')\n",
    "    ax1.set_xlabel('Grau polinomial')\n",
    "    ax1.set_ylabel('RMSE (validação)')\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(list(degrees), feats_by_d, marker='x')\n",
    "    ax2.set_ylabel('Nº de features')\n",
    "    plt.title('RMSE vs Grau (linha) e Nº de Features (cruzes)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return best_model, best_rmse, results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5810bbd",
   "metadata": {},
   "source": [
    "### Run: LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a748b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lin_model, best_lin_rmse, lin_results = validate_poly_regression(\n",
    "    X_tr, y_tr, X_va, y_va,\n",
    "    regressor='linear',\n",
    "    degrees=range(1,15),\n",
    "    subset_frac=0.15,\n",
    "    random_state=SEED\n",
    ")\n",
    "print('\\nMelhor (Linear): RMSE_val =', best_lin_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdb2066",
   "metadata": {},
   "source": [
    "### Run: RidgeCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a90f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ridge_model, best_ridge_rmse, ridge_results = validate_poly_regression(\n",
    "    X_tr, y_tr, X_va, y_va,\n",
    "    regressor='ridge',\n",
    "    degrees=range(1,15),\n",
    "    subset_frac=0.15,\n",
    "    random_state=SEED\n",
    ")\n",
    "print('\\nMelhor (RidgeCV): RMSE_val =', best_ridge_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574b1bb4",
   "metadata": {},
   "source": [
    "### 10 execuções (distribuição do grau ótimo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c3d197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_many(n_runs=10, regressor='ridge', subset_frac=0.10, degrees=range(1,15)):\n",
    "    best_degrees = []\n",
    "    best_rmses   = []\n",
    "    for i in range(n_runs):\n",
    "        seed_i = SEED + i\n",
    "        model, rmse, res = validate_poly_regression(\n",
    "            X_tr, y_tr, X_va, y_va,\n",
    "            regressor=regressor,\n",
    "            degrees=degrees,\n",
    "            subset_frac=subset_frac,\n",
    "            random_state=seed_i\n",
    "        )\n",
    "        d_best = min(res.keys(), key=lambda d: res[d]['rmse'])\n",
    "        best_degrees.append(d_best)\n",
    "        best_rmses.append(rmse)\n",
    "        print(f\"[Run {i+1:02d}] Best degree = {d_best} | RMSE_val = {rmse:.6f}\")\n",
    "    return np.array(best_degrees), np.array(best_rmses)\n",
    "\n",
    "best_deg_ridge, best_rmse_ridge = run_many(n_runs=10, regressor='ridge', subset_frac=0.10)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(best_deg_ridge, bins=np.arange(0.5,14.6,1), rwidth=0.85)\n",
    "plt.xticks(range(1,15))\n",
    "plt.xlabel('Grau selecionado (RidgeCV)')\n",
    "plt.ylabel('Frequência em 10 execuções')\n",
    "plt.title('Distribuição do grau ótimo (amostra 10 execuções)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('Graus escolhidos (RidgeCV):', best_deg_ridge.tolist())\n",
    "print('Mais frequente:', int(pd.Series(best_deg_ridge).mode().iloc[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
